{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b0d3bdff101d217",
   "metadata": {},
   "source": [
    "## Hierarchical Bayesian Modeling for EA metrics for tribal knowledge silos  \n",
    "\n",
    "In this analysis, we will try to create a methodology and data-driven metric for identifying potential technological risks within an organization's coding protocols. We'll examine how programming languages are utilised across various projects and repositories, similar to those found in code repositories such as GitHub,  and leverage Hierarchical Bayesian Modelling (HBM) for multi-level data analysis. \n",
    "\n",
    "HBM effectively captures project-specific variances and overall project trends, providing a nuanced \"risk\" metric for Enterprise Architecture. This enables organisations to identify potential knowledge silos and make strategic decisions to enhance project continuity and organisational adaptability.\n",
    "\n",
    "By analysing language usage across different organisational levels and integrating uncertainty, HBM aims to expose pockets of siloed tribal knowledge (in this example, via a proxy of languages used, but can easily be extended to accommodate other features such a #of commits, time since last commit, total commits, etc., etc.), which is crucial for identifying hidden risks within the architectural framework. This analysis uncovers potential vulnerabilities and compares language usage at repository and project scales against wider organisational patterns. These comparative insights are critical, revealing when a technology may seem insignificant in isolation emerges as a considerable risk in the broader organisational context due to limited expertise or exposure. This comprehensive examination ensures that technology decisions are made with a strategic perspective, reinforcing organisational resilience in the face of technological evolution.\n",
    "\n",
    "For a more concrete example, consider a scenario where an organisation's repository primarily uses Haskell, a language not commonly used in broader enterprise contexts. Hierarchical Bayesian Modelling evaluates the risk by scrutinising Haskell's application within the repository, its relevance to the project, and its organisational prevalence. This comprehensive assessment ascertains the alignment of Haskell's use with the enterprise's technological trajectory and knowledge base, guiding strategic architectural decisions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee99bdbedd31ef3",
   "metadata": {},
   "source": [
    "#### Flow\n",
    "To start building a hierarchical Bayesian model using PyMC3 based on your JSON data, you'll first need to parse the data to extract the relevant information for modelling. This involves aggregating language usage across repositories and projects. After that, we define a hierarchical model that captures the variability within repositories and commonalities across projects.\n",
    "\n",
    "* Data Preparation: Aggregate the language bytes for each language across all repositories and projects.\n",
    "* Model Definition: Define a hierarchical model in Pymc, using project-level priors influencing repository-level distributions.\n",
    "* Inference: Use MCMC provided by pymc to sample from the posterior distribution.\n",
    "* Analysis: Analyze the posterior distributions to identify languages with usage outside the credible regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64929205d7d6c912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "\n",
    "import polars as pl\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import pprint\n",
    "\n",
    "from utils import load_data, json2polars\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9b0862-2954-49f3-a206-e69b84cddea7",
   "metadata": {},
   "source": [
    "## Pre-Processing\n",
    "The first step is to run the `generate_dummy_data.py` file to make sure we have data to play around with, the generated dummy data is similar to what you might pull from GitHub's REST API for repository languages https://docs.github.com/en/rest/repos/repos?apiVersion=2022-11-28#list-repository-languages\n",
    "\n",
    "```GitHub CLI api\n",
    "https://cli.github.com/manual/gh_api\n",
    "\n",
    "gh api \\\n",
    "  -H \"Accept: application/vnd.github+json\" \\\n",
    "  -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n",
    "  /repos/OWNER/REPO/languages\n",
    "\n",
    "Example Response:\n",
    "{\n",
    "  \"C\": 78769,\n",
    "  \"Python\": 7769\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "From here, we can load and transform the data. In this instance, we will be using `polars` rather than `pandas` dataframes \n",
    "\n",
    "As we are using polars and not pandas, we want to avoid Pandas-style coding and use the Polars Expressions API. \n",
    "Expressions are the heart of Polars and yield the best performance.\n",
    "\n",
    "*N.B.* Here's a section of the User Guide that may help transitioning from Pandas-style coding to using Polars Expressions.\n",
    "https://docs.pola.rs/user-guide/migration/pandas/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bc6912-e1b0-4ff3-bd41-da2c962a92af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json = load_data(\"data/dummy_language_data.json\")\n",
    "# Prety print some Projects and Repos randomly to visualise the data\n",
    "NUM_PROJECTS = 1\n",
    "first_N_projects = {k: df_json[k] for k in list(df_json)[:NUM_PROJECTS]}\n",
    "pp = pprint.PrettyPrinter(depth=3)\n",
    "pp.pprint(first_N_projects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0479e6ad-ad19-4f50-bc99-495b84ea55e2",
   "metadata": {},
   "source": [
    "Let's flip this into a normal dataset we are used to, and and a new variable to log transform the byte count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a57fbc-6bc4-4c72-bb1f-858e38ba2b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=json2polars(df_json)\n",
    "df = df.with_columns(pl.col('ByteCount').log().alias('logByteCount'))\n",
    "print(df.head(n=20))\n",
    "print(\"Total number of projects:\", df['Project'].unique().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74fe316-0f6a-4b26-8623-8f30ecb6b171",
   "metadata": {},
   "source": [
    "## Hierarchical Model Specification\n",
    "Introduction to Hierarchical Bayesian Modelling\n",
    "Defining the hierarchical model structure (e.g., projects as higher-level groups, repositories within projects, and languages within repositories)\n",
    "Explanation of model parameters and priors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6280421-54eb-4c68-8cb1-f28ebb96f6cb",
   "metadata": {},
   "source": [
    "## Model Implementation\n",
    "Implementing the HBM using PyMC3\n",
    "Defining the model in PyMC3\n",
    "Setting up the priors for each level of the hierarchy\n",
    "Incorporating the data into the model\n",
    "Model fitting (e.g., using MCMC methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549433a2-7215-43e3-90f7-f44294519f4f",
   "metadata": {},
   "source": [
    "## Model Diagnostics\n",
    "Checking model convergence (e.g., trace plots, R-hat statistics)\n",
    "Posterior predictive checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527d0d40-f642-4632-875b-4a9395e2491c",
   "metadata": {},
   "source": [
    "##  Results and Interpretation\n",
    "Extracting and summarizing the posterior distributions of model parameters\n",
    "Identifying significant factors and their impacts on language usage risk metrics\n",
    "Ridge plots for visualizing the distribution of language usage across projects and repositories, highlighting potential outliers or risks\n",
    "Additional plots for deeper insights (e.g., comparison of language usage trends across different organizational levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a884ea9-56cf-4070-876a-7f4ae955f318",
   "metadata": {},
   "source": [
    "## Streamlit app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df155dec-0023-41fd-933f-03df830e7b16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
