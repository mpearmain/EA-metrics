{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b0d3bdff101d217",
   "metadata": {},
   "source": [
    "## Hierarchical Bayesian Modeling to assess tribal knowledge\n",
    "\n",
    "In this analysis, we will try to create a methodology and data-driven metric for identifying potential technological risks within an organization's coding protocols. We'll examine how programming languages are utilised across various projects and repositories, similar to those found in code repositories such as GitHub,  and leverage Hierarchical Bayesian Modelling (HBM) for multi-level data analysis. \n",
    "\n",
    "HBM effectively captures project-specific variances and overall project trends, providing a nuanced \"risk\" metric for Enterprise Architecture. This enables organisations to identify potential knowledge silos and make strategic decisions to enhance project continuity and organisational adaptability.\n",
    "\n",
    "By analysing language usage across different organisational levels and integrating uncertainty, HBM aims to expose pockets of siloed tribal knowledge (in this example, via a proxy of languages used, but can easily be extended to accommodate other features such a #of commits, time since last commit, total commits, etc., etc.), which is crucial for identifying hidden risks within the architectural framework. This analysis uncovers potential vulnerabilities and compares language usage at repository and project scales against wider organisational patterns. These comparative insights are critical, revealing when a technology may seem insignificant in isolation emerges as a considerable risk in the broader organisational context due to limited expertise or exposure. This comprehensive examination ensures that technology decisions are made with a strategic perspective, reinforcing organisational resilience in the face of technological evolution.\n",
    "\n",
    "For a more concrete example, consider a scenario where an organisation's repository primarily uses Haskell, a language not commonly used in broader enterprise contexts. Hierarchical Bayesian Modelling evaluates the risk by scrutinising Haskell's application within the repository, its relevance to the project, and its organisational prevalence. This comprehensive assessment ascertains the alignment of Haskell's use with the enterprise's technological trajectory and knowledge base, guiding strategic architectural decisions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee99bdbedd31ef3",
   "metadata": {},
   "source": [
    "#### Flow\n",
    "To start building a hierarchical Bayesian model using PyMC3 based on your JSON data, you'll first need to parse the data to extract the relevant information for modelling. This involves aggregating language usage across repositories and projects. After that, we define a hierarchical model that captures the variability within repositories and commonalities across projects.\n",
    "\n",
    "* Data Preparation: Aggregate the language bytes for each language across all repositories and projects.\n",
    "* Model Definition: Define a hierarchical model in Pymc, using project-level priors influencing repository-level distributions.\n",
    "* Inference: Use MCMC provided by pymc to sample from the posterior distribution.\n",
    "* Analysis: Analyze the posterior distributions to identify languages with usage outside the credible regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64929205d7d6c912",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T04:55:12.460170Z",
     "start_time": "2024-02-27T04:55:12.456226Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import graphviz\n",
    "import arviz as az\n",
    "import pprint\n",
    "\n",
    "from utils import load_data, json2pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9b0862-2954-49f3-a206-e69b84cddea7",
   "metadata": {},
   "source": [
    "## Pre-Processing\n",
    "The first step is to run the `generate_dummy_data.py` file to make sure we have data to play around with, the generated dummy data is similar to what you might pull from GitHub's REST API for repository languages https://docs.github.com/en/rest/repos/repos?apiVersion=2022-11-28#list-repository-languages\n",
    "\n",
    "```GitHub CLI api\n",
    "https://cli.github.com/manual/gh_api\n",
    "\n",
    "gh api \\\n",
    "  -H \"Accept: application/vnd.github+json\" \\\n",
    "  -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n",
    "  /repos/OWNER/REPO/languages\n",
    "\n",
    "Example Response:\n",
    "{\n",
    "  \"C\": 78769,\n",
    "  \"Python\": 7769\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "From here, we can load and transform the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90bc6912-e1b0-4ff3-bd41-da2c962a92af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T04:55:16.064859Z",
     "start_time": "2024-02-27T04:55:16.057668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Project_1': {'Repo_1': {'C#': 901416,\n",
      "                          'Groovy': 2105,\n",
      "                          'Java': 2105704,\n",
      "                          'Kotlin': 814857,\n",
      "                          'Lua': 15832,\n",
      "                          'Rust': 311852,\n",
      "                          'SQL': 592745},\n",
      "               'Repo_10': {'Bash': 2315026,\n",
      "                           'C#': 787532,\n",
      "                           'Dart': 1660530,\n",
      "                           'Kotlin': 870598,\n",
      "                           'Rust': 229314},\n",
      "               'Repo_11': {'C#': 2011185, 'Erlang': 4657070},\n",
      "               'Repo_2': {'Bash': 414472,\n",
      "                          'Elixir': 240387,\n",
      "                          'Go': 407618,\n",
      "                          'JavaScript': 312394,\n",
      "                          'Kotlin': 646016,\n",
      "                          'Python': 1692987,\n",
      "                          'Rails': 59896,\n",
      "                          'TypeScript': 173034},\n",
      "               'Repo_3': {'Rust': 567407, 'Scala': 5777592},\n",
      "               'Repo_4': {'Python': 4159979},\n",
      "               'Repo_5': {'C++': 142304, 'PHP': 166915, 'Python': 219038},\n",
      "               'Repo_6': {'Bash': 1734398,\n",
      "                          'JavaScript': 2286514,\n",
      "                          'Swift': 131361},\n",
      "               'Repo_7': {'C++': 1965721,\n",
      "                          'Elixir': 3,\n",
      "                          'Fortran': 88956,\n",
      "                          'JavaScript': 1383270,\n",
      "                          'Kotlin': 294718,\n",
      "                          'Lua': 12113,\n",
      "                          'MATLAB': 119442,\n",
      "                          'Objective-C': 46675,\n",
      "                          'PowerShell': 747533,\n",
      "                          'Rails': 39494,\n",
      "                          'Ruby': 839924,\n",
      "                          'SQL': 1011207,\n",
      "                          'Swift': 112931,\n",
      "                          'TypeScript': 599383},\n",
      "               'Repo_8': {'C#': 1104430},\n",
      "               'Repo_9': {'C++': 815358, 'Python': 3263742, 'Ruby': 831921}}}\n"
     ]
    }
   ],
   "source": [
    "df_json = load_data(\"data/dummy_language_data.json\")\n",
    "# Prety print some Projects and Repos randomly to visualise the data\n",
    "NUM_PROJECTS = 1\n",
    "first_N_projects = {k: df_json[k] for k in list(df_json)[:NUM_PROJECTS]}\n",
    "pp = pprint.PrettyPrinter(depth=3)\n",
    "pp.pprint(first_N_projects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0479e6ad-ad19-4f50-bc99-495b84ea55e2",
   "metadata": {},
   "source": [
    "Let's flip this into a normal dataset we are used to, and and a new variable to log transform the byte count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8a57fbc-6bc4-4c72-bb1f-858e38ba2b57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T04:55:19.331032Z",
     "start_time": "2024-02-27T04:55:19.315700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Project Repository    Language  ByteCount  logByteCount  \\\n",
      "0   Project_1     Repo_1        Java    2105704     14.560160   \n",
      "1   Project_1     Repo_1         SQL     592745     13.292520   \n",
      "2   Project_1     Repo_1      Groovy       2105      7.652071   \n",
      "3   Project_1     Repo_1        Rust     311852     12.650284   \n",
      "4   Project_1     Repo_1          C#     901416     13.711722   \n",
      "5   Project_1     Repo_1         Lua      15832      9.669788   \n",
      "6   Project_1     Repo_1      Kotlin     814857     13.610768   \n",
      "7   Project_1     Repo_2        Bash     414472     12.934761   \n",
      "8   Project_1     Repo_2      Kotlin     646016     13.378580   \n",
      "9   Project_1     Repo_2      Python    1692987     14.342005   \n",
      "10  Project_1     Repo_2       Rails      59896     11.000365   \n",
      "11  Project_1     Repo_2      Elixir     240387     12.390005   \n",
      "12  Project_1     Repo_2          Go     407618     12.918086   \n",
      "13  Project_1     Repo_2  JavaScript     312394     12.652020   \n",
      "14  Project_1     Repo_2  TypeScript     173034     12.061243   \n",
      "15  Project_1     Repo_3       Scala    5777592     15.569498   \n",
      "16  Project_1     Repo_3        Rust     567407     13.248832   \n",
      "17  Project_1     Repo_4      Python    4159979     15.241021   \n",
      "18  Project_1     Repo_5         PHP     166915     12.025240   \n",
      "19  Project_1     Repo_5      Python     219038     12.297001   \n",
      "\n",
      "        Project_Repo  Project_codes  Repository_codes  Language_codes  \\\n",
      "0   Project_1_Repo_1              0                 0              16   \n",
      "1   Project_1_Repo_1              0                 0              32   \n",
      "2   Project_1_Repo_1              0                 0              13   \n",
      "3   Project_1_Repo_1              0                 0              31   \n",
      "4   Project_1_Repo_1              0                 0               2   \n",
      "5   Project_1_Repo_1              0                 0              20   \n",
      "6   Project_1_Repo_1              0                 0              19   \n",
      "7   Project_1_Repo_2              0                 7               1   \n",
      "8   Project_1_Repo_2              0                 7              19   \n",
      "9   Project_1_Repo_2              0                 7              27   \n",
      "10  Project_1_Repo_2              0                 7              29   \n",
      "11  Project_1_Repo_2              0                 7               7   \n",
      "12  Project_1_Repo_2              0                 7              12   \n",
      "13  Project_1_Repo_2              0                 7              17   \n",
      "14  Project_1_Repo_2              0                 7              35   \n",
      "15  Project_1_Repo_3              0                 8              33   \n",
      "16  Project_1_Repo_3              0                 8              31   \n",
      "17  Project_1_Repo_4              0                 9              27   \n",
      "18  Project_1_Repo_5              0                10              24   \n",
      "19  Project_1_Repo_5              0                10              27   \n",
      "\n",
      "    Project_Repo_codes  \n",
      "0                   96  \n",
      "1                   96  \n",
      "2                   96  \n",
      "3                   96  \n",
      "4                   96  \n",
      "5                   96  \n",
      "6                   96  \n",
      "7                   99  \n",
      "8                   99  \n",
      "9                   99  \n",
      "10                  99  \n",
      "11                  99  \n",
      "12                  99  \n",
      "13                  99  \n",
      "14                  99  \n",
      "15                 100  \n",
      "16                 100  \n",
      "17                 101  \n",
      "18                 102  \n",
      "19                 102  \n",
      "Total number of projects: (40,)\n",
      "Total number of projects repo ids: (404,)\n"
     ]
    }
   ],
   "source": [
    "df=json2pandas(df_json)\n",
    "# Using pandas to calculate the logarithm of the ByteCount column\n",
    "df['logByteCount'] = np.log(df['ByteCount'])\n",
    "# Creating a new column Project_Repo by concatenating Project and Repository columns\n",
    "df['Project_Repo'] = df['Project'] + \"_\" + df['Repository']\n",
    "\n",
    "columns_to_encode = ['Project', 'Repository', 'Language', 'Project_Repo']\n",
    "\n",
    "# Loop over the columns to encode\n",
    "for column_name in columns_to_encode:\n",
    "    # Cast each column to Categorical and add it as a new column with a suffix '_codes'\n",
    "    df[f'{column_name}_codes'] = df[column_name].astype('category').cat.codes\n",
    "\n",
    "    \n",
    "print(df.head(n=20))\n",
    "print(\"Total number of projects:\", df['Project'].unique().shape)\n",
    "print(\"Total number of projects repo ids:\", df['Project_Repo_codes'].unique().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74fe316-0f6a-4b26-8623-8f30ecb6b171",
   "metadata": {},
   "source": [
    "## Hierarchical Model Specification\n",
    "\n",
    "This section introduces Hierarchical Bayesian Modelling (HBM) principles and their application in structuring complex, multi-level datasets, such as those encountered in evaluating technological risks within coding languages.\n",
    "\n",
    "#### Introduction to Hierarchical Bayesian Modelling\n",
    "Hierarchical Bayesian Modelling is a statistical framework that enables data analysis across different levels of hierarchy by integrating the variability within individual units (such as repositories) and the commonalities across groups (such as projects, domains, or departments). Bayes' theorem is at the core of Bayesian inference, which updates the probability for a hypothesis as more evidence becomes available. One of the critical concepts in HBM is exchangeability, which implies that data points are probabilistically symmetrical. This makes it suitable for modelling data that doesn't have a natural ordering or grouping but is considered identically distributed given some unknown parameters.\n",
    "\n",
    "When we analyse the usage of programming languages, we're looking at a hierarchical model structure with multiple layers. Given that the `ByteCount` variable represents the number of bytes of code for a given language in a repository, it essentially counts data (albeit at a potentially large scale that we might want to log-transform later). Count data is often modelled using distributions specifically suited to non-negative integer values, such as the Negative Binomial, leading us to represent our model as a Hierarchical Beta-Negative Binomial Model.\n",
    "\n",
    "These layers represent language usage within repositories, which are nested within projects.\n",
    "\n",
    "- **Level 1 - Repository-Level Likelihood:** At this level, we describe the observed data, such as the amount of code written in each language within a repository, using a likelihood function.\n",
    "\n",
    "  $$ P(Language_{ij} | \\theta_{ij}) \\sim NegativeBinomial(\\mu_{ij}, \\alpha) $$\n",
    "\n",
    "  Here, \\( \\theta_{ij} \\) represents the expected byte count for language usage, where \\( i \\) denotes the repository and \\( j \\) the language. \\( \\mu_{ij} \\) is the mean parameter and \\( \\alpha \\) is the dispersion parameter of the Negative Binomial distribution.\n",
    "\n",
    "- **Level 2 - Project-Level Priors:** As we move up to the project level, parameters from the repository level are considered uncertain and are described by priors.\n",
    "\n",
    "  $$ \\mu_{ij} | \\mu_i, \\kappa_i \\sim Beta(\\mu_i \\kappa_i, (1 - \\mu_i) \\kappa_i) $$\n",
    "\n",
    "  The Beta distribution parameters \\( \\mu_i \\) and \\( \\kappa_i \\) represent the expected language usage and variability within a project, influencing the mean parameter \\( \\mu_{ij} \\) of the Negative Binomial distribution at the repository level.\n",
    "\n",
    "- **Level 3 - Organisational-Level Hyperpriors:** At the organisational level, we look at the broader patterns in language usage across all projects.\n",
    "\n",
    "  $$ \\mu_i \\sim Beta(a_{\\mu}, b_{\\mu}) $$\n",
    "  $$ \\kappa_i \\sim Gamma(a_{\\kappa}, b_{\\kappa}) $$\n",
    "\n",
    "  Hyperpriors for \\( \\mu_i \\) and \\( \\kappa_i \\) reflect our assumptions about these patterns before analysing the data.\n",
    "\n",
    "This hierarchical approach allows for a detailed analysis of organisational language usage. We're not just modelling individual repositories but also capturing trends across projects and the entire organisation.\n",
    "\n",
    "#### Explanation of Model Parameters and Priors\n",
    "\n",
    "Hierarchical Bayesian Modelling (HBM) views parameters as distributions, known as priors. Priors represent our initial beliefs or understanding about the parameters before examining the data. When dealing with count data, such as the count of bytes of code in different programming languages within repositories, overdispersion is often observed in such data. A Negative Binomial distribution can account for this overdispersion.\n",
    "\n",
    "The model includes hyperparameters, such as the mean parameter  \\($ \\mu $\\)  for the Negative Binomial distribution. These hyperparameters introduce a layer of variability accounting for differences within repositories and across projects. Moreover, these hyperparameters are informed by higher-level distributions, or hyperpriors. For example, a Beta distribution might be used to model project-level variability, influencing the Negative Binomial's mean parameter \\( $\\mu $\\), while a Gamma distribution is applied to the dispersion parameter \\($ \\alpha $\\), relating to the variability of byte counts.\n",
    "\n",
    "Employing this type of hierarchical model enables the refinement of our initial beliefs in light of collected data, leading to a deeper and more nuanced understanding of an organisation's coding practices. The adaptability of this model to new information enhances the precision of our insights, effectively capturing both the average and the variance of language usage within the complex hierarchical structure of repositories and projects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f666c696-acdd-48d5-ba48-dfd4480b6f0d",
   "metadata": {},
   "source": [
    "\n",
    "## Transitioning to Posterior Distributions\n",
    "\n",
    "### From Theory to Practice: The Role of Posterior Distributions\n",
    "\n",
    "With our model parameters defined and their priors set, the next step in Bayesian analysis is to update these beliefs with observed data. This is where the posterior distribution comes into play.\n",
    "\n",
    "\n",
    "#### What is the posterior?\n",
    "\n",
    "In the hierarchical Bayesian modelling (HBM) context, the posterior distribution is the updated belief about our model's parameters after considering the observed data. It combines our prior beliefs (the priors) and the evidence from the data (the likelihood). Mathematically, it is expressed as:\n",
    "\n",
    "$$\n",
    "P(\\theta | data) \\propto P(data | \\theta) \\times P(\\theta)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- \\($ P(\\theta | data) $\\) is the posterior distribution of the parameters \\($ \\theta $\\).\n",
    "- \\($ P(data | \\theta) $\\) is the likelihood of the data given the parameters.\n",
    "- \\($ P(\\theta) $\\) is the prior distribution of the parameters.\n",
    "\n",
    "After observing the data, the posterior distribution provides a range of likely values for the parameters, which is crucial for making informed decisions.\n",
    "\n",
    "\n",
    "### Practical Implications of Posterior Analysis in Hierarchical Bayesian Modelling\n",
    "\n",
    "Through the lens of Hierarchical Bayesian Modelling, the posterior distribution becomes a beacon, illuminating the path to understanding and action within an organisation's coding practices.\n",
    "\n",
    "\n",
    "### Informing Strategic Decision-Making\n",
    "\n",
    "The power of posterior analysis extends beyond diagnostics; it informs strategic resource allocation and risk management:\n",
    "\n",
    "- **Credible Intervals**: The precision of parameter estimates, reflected in the credible intervals of the posterior distribution, directs our focus to areas where additional data collection or deeper investigation may be warranted.\n",
    "\n",
    "- **Outlier Detection**: Spotting outliers within posterior distributions alerts us to unconventional language usage patterns. These could represent areas of innovation warranting further exploration or potential risks if the languages in question lack broad support.\n",
    "\n",
    "- **Strategic Resource Allocation**: Insights gained from posterior distributions enable informed decisions on resource allocation—be it for targeted training programmes, strategic hiring to build expertise in underutilised languages, or investment in technology stacks that promise to align with and propel the organisation's strategic objectives.\n",
    "\n",
    "Interpreting the posterior distributions derived from our hierarchical model does more than just enhance our understanding of language usage; it equips us to forecast, plan, and foster a coding environment that is both efficient and resilient to future challenges.\n",
    "\n",
    "### Uncovering Knowledge Silos\n",
    "\n",
    "The posterior distributions for language usage within repositories serve as a diagnostic tool, revealing languages that are disproportionately relied upon. Anomalies in these distributions may signal the existence of knowledge silos, suggesting areas where diversification and training could be beneficial. By identifying these silos, we can proactively address potential bottlenecks in knowledge transfer and code maintenance.\n",
    "\n",
    "### Assessing Project-Level Variability\n",
    "\n",
    "The consistency of coding practices across repositories within projects is characterised by project-level hyperparameters. When significant variability is observed in these posterior distributions, it may reflect fragmented coding practices that could undermine team collaboration and project efficiency. This insight drives us to review and possibly revise coding standards, ensuring that practices are aligned and conducive to project success.\n",
    "\n",
    "### Evaluating Organisational Coding Norms\n",
    "\n",
    "At the highest organisational level, posterior distributions offer a macro perspective of coding culture and norms. Deviations in these distributions can reveal organisational preferences or aversions towards specific languages. Understanding these trends is critical for shaping future strategies in technology adoption, capability development, and training initiatives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6280421-54eb-4c68-8cb1-f28ebb96f6cb",
   "metadata": {},
   "source": [
    "## Model Implementation\n",
    "- Implementing the HBM using PyMC3\n",
    "- Defining the model in PyMC3\n",
    "- Setting up the priors for each level of the hierarchy\n",
    "- Incorporating the data into the model\n",
    "- Model fitting (e.g., using MCMC methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cc360bd-a6f5-49ab-a82b-9a8379efa9da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T06:23:43.619461Z",
     "start_time": "2024-02-27T06:23:43.590571Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_languages: 37, n_projects: 40, n_repos: 15\n",
      "avg_byte_per_language:    Language_codes     ByteCount    logByte\n",
      "0               0  1.014471e+06  13.829878\n",
      "1               1  1.615548e+06  14.295185\n",
      "2               2  1.407680e+06  14.157453\n",
      "3               3  1.466691e+06  14.198520\n",
      "4               4  1.012108e+06  13.827546\n",
      " avg_byte_per_project:    Project_codes     ByteCount    logByte\n",
      "0              0  1.013978e+06  13.829391\n",
      "1              1  1.306852e+06  14.083132\n",
      "2              2  8.610294e+05  13.665884\n",
      "3              3  1.139761e+06  13.946329\n",
      "4              4  1.219516e+06  14.013964\n",
      " avg_byte_per_repo:    Repository_codes     ByteCount    logByte\n",
      "0                 0  1.479278e+06  14.207065\n",
      "1                 1  1.389882e+06  14.144729\n",
      "2                 2  1.301123e+06  14.078738\n",
      "3                 3  1.006541e+06  13.822030\n",
      "4                 4  1.401065e+06  14.152743\n",
      " avg_byte_per_projrepo:    Project_Repo_codes     ByteCount    logByte\n",
      "0                   0  2.465840e+06  14.718043\n",
      "1                   1  5.216284e+05  13.164711\n",
      "2                   2  4.811559e+06  15.386532\n",
      "3                   3  4.866594e+05  13.095320\n",
      "4                   4  2.771772e+06  14.834997\n",
      "\n",
      "\n",
      "project_idx shape: (1740,), repo_idx shape: (1740,), languages_idx shape: (1740,)\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df' is your DataFrame and necessary imports are done\n",
    "n_projects = df['Project_codes'].nunique()\n",
    "n_repos = df['Repository_codes'].nunique()\n",
    "n_project_repos = df['Project_Repo_codes'].nunique()\n",
    "n_languages = df['Language_codes'].nunique()\n",
    "\n",
    "# Calculate average byte count per language as a starting point\n",
    "avg_byte_per_language = df.groupby('Language_codes')['ByteCount'].mean().reset_index()\n",
    "avg_byte_per_language['logByte'] = np.log(avg_byte_per_language['ByteCount'])\n",
    "\n",
    "# Calculate average byte count per project\n",
    "avg_byte_per_project = df.groupby('Project_codes')['ByteCount'].mean().reset_index()\n",
    "avg_byte_per_project['logByte'] = np.log(avg_byte_per_project['ByteCount'])\n",
    "\n",
    "# Calculate average byte count per repository\n",
    "avg_byte_per_repo = df.groupby('Repository_codes')['ByteCount'].mean().reset_index()\n",
    "avg_byte_per_repo['logByte'] = np.log(avg_byte_per_repo['ByteCount'])\n",
    "\n",
    "# Calculate average byte count per project per repository\n",
    "avg_byte_per_projrepo = df.groupby('Project_Repo_codes')['ByteCount'].mean().reset_index()\n",
    "avg_byte_per_projrepo['logByte'] = np.log(avg_byte_per_projrepo['ByteCount'])\n",
    "\n",
    "project_idx = df['Project_codes'].values\n",
    "repo_idx = df['Repository_codes'].values\n",
    "languages_idx = df['Language_codes'].values\n",
    "byte_count = df['ByteCount'].values\n",
    "\n",
    "# Outside the model, verify shapes and values directly in Python\n",
    "print(f'n_languages: {n_languages}, n_projects: {n_projects}, n_repos: {n_repos}')\n",
    "print(f'avg_byte_per_language: {avg_byte_per_language.head(5)}\\n',  \n",
    "      f'avg_byte_per_project: {avg_byte_per_project.head(5)}\\n', \n",
    "      f'avg_byte_per_repo: {avg_byte_per_repo.head(5)}\\n', \n",
    "      f'avg_byte_per_projrepo: {avg_byte_per_projrepo.head(5)}\\n\\n')\n",
    "print(f'project_idx shape: {project_idx.shape}, repo_idx shape: {repo_idx.shape}, languages_idx shape: {languages_idx.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b882230e-57d8-4bf4-8cdd-4ec72954db01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytensor\n",
    "\n",
    "# Example of setting a PyTensor configuration option for debugging\n",
    "pytensor.config.exception_verbosity = 'high'\n",
    "\n",
    "# Build the model\n",
    "with pm.Model() as language_usage_model:\n",
    "    # Define organisational-level hyperpriors that influence project-level parameters\n",
    "    # These represent our assumptions about the variability across all projects\n",
    "    a_mu = pm.Gamma('a_mu', alpha=1.0, beta=1.0, initval=2.0)\n",
    "    b_mu = pm.Gamma('b_mu', alpha=1.0, beta=1.0, initval=2.0)\n",
    "    a_kappa = pm.Gamma('a_kappa', alpha=1.0, beta=0.1, initval=2.0)\n",
    "    b_kappa = pm.Gamma('b_kappa', alpha=1.0, beta=0.1, initval=2.0)\n",
    "\n",
    "    # Language-Level Priors\n",
    "    # Assuming each language has an associated effect on the byte counts\n",
    "    language_effect = pm.Normal('language_effect', mu=0, sigma=1, shape=n_languages)\n",
    "    \n",
    "    # Define project-level priors that capture the mean and variability of language usage within each project\n",
    "    # 'mu_project' represents the expected proportion of language usage within projects\n",
    "    # 'kappa_project' captures the variability of language usage within projects\n",
    "    mu_project = pm.Beta('mu_project', alpha=a_mu, beta=b_mu, shape=n_projects)\n",
    "    kappa_project = pm.Gamma('kappa_project', alpha=a_kappa, beta=b_kappa, shape=n_projects)\n",
    "    \n",
    "    \n",
    "    # Define repository-level effects influenced by their respective projects 'theta_repo' represents the expected\n",
    "    # Proportion of language usage within each repository, influenced by the project to which it belongs.\n",
    "    theta_repo = pm.Beta('theta_repo', alpha=mu_project[project_idx] * kappa_project[project_idx], \n",
    "                         beta=(1 - mu_project[project_idx]) * kappa_project[project_idx], \n",
    "                         shape=n_repos)\n",
    "    \n",
    "    # Repository-Level Likelihood adjusted for language effect\n",
    "    # Here, we assume that the byte counts are influenced by both the repository effect and the language effect\n",
    "    mu_repo_lang = theta_repo[repo_idx] + language_effect[languages_idx]\n",
    "        \n",
    "    # Define the dispersion parameter for the Negative Binomial distribution to account for overdispersion in the byte counts 'dispersion_factor' controls the variance of the\n",
    "    # Negative Binomial distribution independently from the mean\n",
    "    dispersion_factor = pm.Exponential('dispersion_factor', lam=1.0)\n",
    "     # The Negative Binomial distribution models the observed byte counts, now influenced by both repository and language effects\n",
    "    language_count = pm.NegativeBinomial('language_count', mu=mu_repo_lang, alpha=dispersion_factor, observed=byte_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb90ed6-45c6-4168-b09a-62dc09530702",
   "metadata": {},
   "source": [
    "Here’s the graphical representation of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02f96ae5-f91b-4f08-b491-38a1e50d70d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (20230911.1827)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"627pt\" height=\"548pt\"\n",
       " viewBox=\"0.00 0.00 627.07 547.79\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 543.79)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-543.79 623.07,-543.79 623.07,4 -4,4\"/>\n",
       "<text text-anchor=\"middle\" x=\"309.54\" y=\"-33\" font-family=\"Helvetica,sans-Serif\" font-size=\"20.00\">Hierarchical Language Usage Model</text>\n",
       "<text text-anchor=\"middle\" x=\"309.54\" y=\"-9\" font-family=\"Helvetica,sans-Serif\" font-size=\"20.00\">Bayesian Model Visualization</text>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster37</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M461.07,-189.89C461.07,-189.89 599.07,-189.89 599.07,-189.89 605.07,-189.89 611.07,-195.89 611.07,-201.89 611.07,-201.89 611.07,-295.77 611.07,-295.77 611.07,-301.77 605.07,-307.77 599.07,-307.77 599.07,-307.77 461.07,-307.77 461.07,-307.77 455.07,-307.77 449.07,-301.77 449.07,-295.77 449.07,-295.77 449.07,-201.89 449.07,-201.89 449.07,-195.89 455.07,-189.89 461.07,-189.89\"/>\n",
       "<text text-anchor=\"middle\" x=\"596.32\" y=\"-196.34\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">37</text>\n",
       "</g>\n",
       "<g id=\"clust4\" class=\"cluster\">\n",
       "<title>cluster1740</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M289.07,-64C289.07,-64 427.07,-64 427.07,-64 433.07,-64 439.07,-70 439.07,-76 439.07,-76 439.07,-169.89 439.07,-169.89 439.07,-175.89 433.07,-181.89 427.07,-181.89 427.07,-181.89 289.07,-181.89 289.07,-181.89 283.07,-181.89 277.07,-175.89 277.07,-169.89 277.07,-169.89 277.07,-76 277.07,-76 277.07,-70 283.07,-64 289.07,-64\"/>\n",
       "<text text-anchor=\"middle\" x=\"417.57\" y=\"-70.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1740</text>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\">\n",
       "<title>cluster15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M157.07,-189.89C157.07,-189.89 255.07,-189.89 255.07,-189.89 261.07,-189.89 267.07,-195.89 267.07,-201.89 267.07,-201.89 267.07,-295.77 267.07,-295.77 267.07,-301.77 261.07,-307.77 255.07,-307.77 255.07,-307.77 157.07,-307.77 157.07,-307.77 151.07,-307.77 145.07,-301.77 145.07,-295.77 145.07,-295.77 145.07,-201.89 145.07,-201.89 145.07,-195.89 151.07,-189.89 157.07,-189.89\"/>\n",
       "<text text-anchor=\"middle\" x=\"252.32\" y=\"-196.34\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">15</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster40</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M83.07,-315.77C83.07,-315.77 341.07,-315.77 341.07,-315.77 347.07,-315.77 353.07,-321.77 353.07,-327.77 353.07,-327.77 353.07,-421.66 353.07,-421.66 353.07,-427.66 347.07,-433.66 341.07,-433.66 341.07,-433.66 83.07,-433.66 83.07,-433.66 77.07,-433.66 71.07,-427.66 71.07,-421.66 71.07,-421.66 71.07,-327.77 71.07,-327.77 71.07,-321.77 77.07,-315.77 83.07,-315.77\"/>\n",
       "<text text-anchor=\"middle\" x=\"338.32\" y=\"-322.22\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">40</text>\n",
       "</g>\n",
       "<!-- b_kappa -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>b_kappa</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"268.07\" cy=\"-500.72\" rx=\"45.79\" ry=\"39.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"268.07\" y=\"-511.05\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b_kappa</text>\n",
       "<text text-anchor=\"middle\" x=\"268.07\" y=\"-495.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"268.07\" y=\"-479.55\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Gamma</text>\n",
       "</g>\n",
       "<!-- kappa_project -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>kappa_project</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"277.07\" cy=\"-386.59\" rx=\"68.06\" ry=\"39.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"277.07\" y=\"-396.91\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">kappa_project</text>\n",
       "<text text-anchor=\"middle\" x=\"277.07\" y=\"-381.16\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"277.07\" y=\"-365.41\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Gamma</text>\n",
       "</g>\n",
       "<!-- b_kappa&#45;&gt;kappa_project -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>b_kappa&#45;&gt;kappa_project</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M271.14,-461.45C271.77,-453.68 272.43,-445.41 273.08,-437.32\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"276.55,-437.83 273.86,-427.58 269.57,-437.27 276.55,-437.83\"/>\n",
       "</g>\n",
       "<!-- b_mu -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>b_mu</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"42.07\" cy=\"-500.72\" rx=\"42.07\" ry=\"39.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"42.07\" y=\"-511.05\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b_mu</text>\n",
       "<text text-anchor=\"middle\" x=\"42.07\" y=\"-495.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"42.07\" y=\"-479.55\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Gamma</text>\n",
       "</g>\n",
       "<!-- mu_project -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>mu_project</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"135.07\" cy=\"-386.59\" rx=\"56.39\" ry=\"39.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"135.07\" y=\"-396.91\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mu_project</text>\n",
       "<text text-anchor=\"middle\" x=\"135.07\" y=\"-381.16\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"135.07\" y=\"-365.41\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Beta</text>\n",
       "</g>\n",
       "<!-- b_mu&#45;&gt;mu_project -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>b_mu&#45;&gt;mu_project</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M67.49,-469.08C77.54,-456.96 89.25,-442.84 100.08,-429.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"102.75,-432.04 106.44,-422.11 97.36,-427.58 102.75,-432.04\"/>\n",
       "</g>\n",
       "<!-- a_mu -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>a_mu</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"144.07\" cy=\"-500.72\" rx=\"42.07\" ry=\"39.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"144.07\" y=\"-511.05\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a_mu</text>\n",
       "<text text-anchor=\"middle\" x=\"144.07\" y=\"-495.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"144.07\" y=\"-479.55\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Gamma</text>\n",
       "</g>\n",
       "<!-- a_mu&#45;&gt;mu_project -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>a_mu&#45;&gt;mu_project</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M141,-461.45C140.38,-453.68 139.71,-445.41 139.06,-437.32\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"142.57,-437.27 138.28,-427.58 135.59,-437.83 142.57,-437.27\"/>\n",
       "</g>\n",
       "<!-- dispersion_factor -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>dispersion_factor</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"358.07\" cy=\"-260.7\" rx=\"80.79\" ry=\"39.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"358.07\" y=\"-271.03\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">dispersion_factor</text>\n",
       "<text text-anchor=\"middle\" x=\"358.07\" y=\"-255.28\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"358.07\" y=\"-239.53\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Exponential</text>\n",
       "</g>\n",
       "<!-- language_count -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>language_count</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"358.07\" cy=\"-134.82\" rx=\"72.83\" ry=\"39.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"358.07\" y=\"-145.14\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">language_count</text>\n",
       "<text text-anchor=\"middle\" x=\"358.07\" y=\"-129.39\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"358.07\" y=\"-113.64\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">NegBinomial</text>\n",
       "</g>\n",
       "<!-- dispersion_factor&#45;&gt;language_count -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>dispersion_factor&#45;&gt;language_count</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M358.07,-221.18C358.07,-209.88 358.07,-197.36 358.07,-185.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"361.57,-185.83 358.07,-175.83 354.57,-185.83 361.57,-185.83\"/>\n",
       "</g>\n",
       "<!-- a_kappa -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>a_kappa</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"377.07\" cy=\"-500.72\" rx=\"44.72\" ry=\"39.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"377.07\" y=\"-511.05\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a_kappa</text>\n",
       "<text text-anchor=\"middle\" x=\"377.07\" y=\"-495.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"377.07\" y=\"-479.55\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Gamma</text>\n",
       "</g>\n",
       "<!-- a_kappa&#45;&gt;kappa_project -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>a_kappa&#45;&gt;kappa_project</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M350.01,-469.38C339.29,-457.35 326.77,-443.31 315.16,-430.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"317.96,-428.18 308.69,-423.05 312.74,-432.84 317.96,-428.18\"/>\n",
       "</g>\n",
       "<!-- language_effect -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>language_effect</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"530.07\" cy=\"-260.7\" rx=\"72.83\" ry=\"39.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"530.07\" y=\"-271.03\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">language_effect</text>\n",
       "<text text-anchor=\"middle\" x=\"530.07\" y=\"-255.28\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"530.07\" y=\"-239.53\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- language_effect&#45;&gt;language_count -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>language_effect&#45;&gt;language_count</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M493.97,-226.74C480.04,-214.62 463.71,-201.12 448.07,-189.89 438.33,-182.88 427.64,-175.9 417.14,-169.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"419.24,-166.58 408.88,-164.36 415.6,-172.56 419.24,-166.58\"/>\n",
       "</g>\n",
       "<!-- theta_repo -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>theta_repo</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"206.07\" cy=\"-260.7\" rx=\"53.21\" ry=\"39.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"206.07\" y=\"-271.03\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">theta_repo</text>\n",
       "<text text-anchor=\"middle\" x=\"206.07\" y=\"-255.28\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"206.07\" y=\"-239.53\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Beta</text>\n",
       "</g>\n",
       "<!-- kappa_project&#45;&gt;theta_repo -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>kappa_project&#45;&gt;theta_repo</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M256.15,-349.09C248.58,-335.88 239.94,-320.8 231.99,-306.93\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"235.11,-305.34 227.11,-298.4 229.04,-308.82 235.11,-305.34\"/>\n",
       "</g>\n",
       "<!-- mu_project&#45;&gt;theta_repo -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>mu_project&#45;&gt;theta_repo</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M155.61,-349.76C163.25,-336.41 172.03,-321.1 180.1,-307.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"183.14,-308.76 185.08,-298.34 177.07,-305.28 183.14,-308.76\"/>\n",
       "</g>\n",
       "<!-- theta_repo&#45;&gt;language_count -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>theta_repo&#45;&gt;language_count</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M231.97,-226.48C242.44,-214.19 255.1,-200.65 268.07,-189.89 277,-182.47 287.05,-175.41 297.12,-168.97\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"298.8,-172.04 305.45,-163.8 295.11,-166.1 298.8,-172.04\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x24bfe68ba10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming 'language_usage_model' is your PyMC model\n",
    "model_graph = pm.model_to_graphviz(language_usage_model)\n",
    "\n",
    "# Customize the graph - Example changes\n",
    "model_graph.attr(label='Hierarchical Language Usage Model\\nBayesian Model Visualization')\n",
    "model_graph.attr(fontsize='20', color='blue', fontname=\"Helvetica\")\n",
    "\n",
    "# Node and Edge customizations\n",
    "with model_graph.subgraph() as s:\n",
    "    s.attr(rank='same')\n",
    "    # Customize nodes\n",
    "    s.node_attr.update(color='lightblue2', style='filled', fontname=\"Helvetica\")\n",
    "    # Customize edges\n",
    "    s.edge_attr.update(color='gray', arrowsize='0.5')\n",
    "\n",
    "# Render the graph \n",
    "model_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8b207c9-e05c-43cb-9114-c4b3e660d3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VCB\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\tribal-knowledge-tLBhIDXi-py3.11\\Lib\\site-packages\\pytensor\\tensor\\rewriting\\shape.py:158: UserWarning: Failed to infer_shape from Op Mul.\n",
      "Input shapes: [(TensorConstant(TensorType(int64, shape=()), data=array(15, ... ype=int64)),), (TensorConstant(TensorType(int64, shape=()), data=array(1740 ... ype=int64)),)]\n",
      "Exception encountered during infer_shape: <class 'ValueError'>\n",
      "Exception message: Could not broadcast dimensions. Incompatible shapes were [(TensorConstant(TensorType(int64, shape=()), data=array(15, ... ype=int64)),), (TensorConstant(TensorType(int64, shape=()), data=array(1740 ... ype=int64)),)].\n",
      "Traceback: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\VCB\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\tribal-knowledge-tLBhIDXi-py3.11\\Lib\\site-packages\\pytensor\\tensor\\rewriting\\shape.py\", line 134, in get_node_infer_shape\n",
      "    o_shapes = shape_infer(\n",
      "               ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\VCB\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\tribal-knowledge-tLBhIDXi-py3.11\\Lib\\site-packages\\pytensor\\tensor\\elemwise.py\", line 809, in infer_shape\n",
      "    out_shape = broadcast_shape(*i_shapes, arrays_are_shapes=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\VCB\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\tribal-knowledge-tLBhIDXi-py3.11\\Lib\\site-packages\\pytensor\\tensor\\extra_ops.py\", line 1471, in broadcast_shape\n",
      "    return broadcast_shape_iter(arrays, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\VCB\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\tribal-knowledge-tLBhIDXi-py3.11\\Lib\\site-packages\\pytensor\\tensor\\extra_ops.py\", line 1552, in broadcast_shape_iter\n",
      "    raise ValueError(\n",
      "ValueError: Could not broadcast dimensions. Incompatible shapes were [(TensorConstant(TensorType(int64, shape=()), data=array(15, ... ype=int64)),), (TensorConstant(TensorType(int64, shape=()), data=array(1740 ... ype=int64)),)].\n",
      "\n",
      "  warn(msg)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "SpecifyShape: Got shape (1740,), expected (15,).\nApply node that caused the error: SpecifyShape(AdvancedSubtensor.0, 15)\nToposort index: 19\nInputs types: [TensorType(float64, shape=(None,)), TensorType(int8, shape=())]\nInputs shapes: [(1740,), ()]\nInputs strides: [(8,), ()]\nInputs values: ['not shown', array(15, dtype=int8)]\nInputs type_num: [12, 1]\nOutputs clients: [[Mul(SpecifyShape.0, AdvancedSubtensor.0)]]\n\nDebug print of the apply node: \nSpecifyShape [id A] <Vector(float64, shape=(15,))>\n ├─ AdvancedSubtensor [id B] <Vector(float64, shape=(?,))>\n │  ├─ Alloc [id C] <Vector(float64, shape=(40,))>\n │  │  ├─ 0.5 [id D] <Scalar(float64, shape=())>\n │  │  └─ 40 [id E] <Scalar(int64, shape=())>\n │  └─ [ 0  0  0 ... 34 34 34] [id F] <Vector(int8, shape=(1740,))>\n └─ 15 [id G] <Scalar(int8, shape=())>\n\nHINT: Re-running with most PyTensor optimizations disabled could provide a back-trace showing when this node was created. This can be done by setting the PyTensor flag 'optimizer=fast_compile'. If that does not work, PyTensor optimizations can be disabled with 'optimizer=None'.\nHINT: Use the PyTensor flag `exception_verbosity=high` for a debug print-out and storage map footprint of this Apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\tribal-knowledge-tLBhIDXi-py3.11\\Lib\\site-packages\\pytensor\\link\\vm.py:406\u001b[0m, in \u001b[0;36mLoop.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m thunk, node, old_storage \u001b[38;5;129;01min\u001b[39;00m zip_longest(\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthunks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_thunk_clear, fillvalue\u001b[38;5;241m=\u001b[39m()\n\u001b[0;32m    405\u001b[0m ):\n\u001b[1;32m--> 406\u001b[0m     \u001b[43mthunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    407\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m old_s \u001b[38;5;129;01min\u001b[39;00m old_storage:\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\tribal-knowledge-tLBhIDXi-py3.11\\Lib\\site-packages\\pytensor\\graph\\op.py:518\u001b[0m, in \u001b[0;36mOp.make_py_thunk.<locals>.rval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;129m@is_thunk_type\u001b[39m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrval\u001b[39m(p\u001b[38;5;241m=\u001b[39mp, i\u001b[38;5;241m=\u001b[39mnode_input_storage, o\u001b[38;5;241m=\u001b[39mnode_output_storage, n\u001b[38;5;241m=\u001b[39mnode):\n\u001b[1;32m--> 518\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39moutputs:\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\tribal-knowledge-tLBhIDXi-py3.11\\Lib\\site-packages\\pytensor\\tensor\\shape.py:461\u001b[0m, in \u001b[0;36mSpecifyShape.perform\u001b[1;34m(self, node, inp, out_)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(xs \u001b[38;5;241m==\u001b[39m s \u001b[38;5;28;01mfor\u001b[39;00m xs, s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape, shape) \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 461\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecifyShape: Got shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mint\u001b[39m(s)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39ms\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39ms\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    463\u001b[0m     )\n\u001b[0;32m    464\u001b[0m out[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n",
      "\u001b[1;31mAssertionError\u001b[0m: SpecifyShape: Got shape (1740,), expected (15,).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Fiting the model with MCMC\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m language_usage_model:\n\u001b[1;32m----> 3\u001b[0m     trace \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inferencedata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\tribal-knowledge-tLBhIDXi-py3.11\\Lib\\site-packages\\pymc\\sampling\\mcmc.py:682\u001b[0m, in \u001b[0;36msample\u001b[1;34m(draws, tune, chains, cores, random_seed, progressbar, step, nuts_sampler, initvals, init, jitter_max_retries, n_init, trace, discard_tuned_samples, compute_convergence_checks, keep_warning_stat, return_inferencedata, idata_kwargs, nuts_sampler_kwargs, callback, mp_ctx, model, **kwargs)\u001b[0m\n\u001b[0;32m    679\u001b[0m         auto_nuts_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    681\u001b[0m initial_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 682\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[43massign_step_methods\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTEP_METHODS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nuts_sampler \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpymc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(step, NUTS):\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\tribal-knowledge-tLBhIDXi-py3.11\\Lib\\site-packages\\pymc\\sampling\\mcmc.py:232\u001b[0m, in \u001b[0;36massign_step_methods\u001b[1;34m(model, step, methods, step_kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m         selected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\n\u001b[0;32m    225\u001b[0m             methods_list,\n\u001b[0;32m    226\u001b[0m             key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m method, var\u001b[38;5;241m=\u001b[39mrv_var, has_gradient\u001b[38;5;241m=\u001b[39mhas_gradient: method\u001b[38;5;241m.\u001b[39m_competence(  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    227\u001b[0m                 var, has_gradient\n\u001b[0;32m    228\u001b[0m             ),\n\u001b[0;32m    229\u001b[0m         )\n\u001b[0;32m    230\u001b[0m         selected_steps\u001b[38;5;241m.\u001b[39msetdefault(selected, [])\u001b[38;5;241m.\u001b[39mappend(var)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstantiate_steppers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\tribal-knowledge-tLBhIDXi-py3.11\\Lib\\site-packages\\pymc\\sampling\\mcmc.py:133\u001b[0m, in \u001b[0;36minstantiate_steppers\u001b[1;34m(model, steps, selected_steps, step_kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m         args \u001b[38;5;241m=\u001b[39m step_kwargs\u001b[38;5;241m.\u001b[39mget(name, {})\n\u001b[0;32m    132\u001b[0m         used_keys\u001b[38;5;241m.\u001b[39madd(name)\n\u001b[1;32m--> 133\u001b[0m         step \u001b[38;5;241m=\u001b[39m \u001b[43mstep_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m         steps\u001b[38;5;241m.\u001b[39mappend(step)\n\u001b[0;32m    136\u001b[0m unused_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(step_kwargs)\u001b[38;5;241m.\u001b[39mdifference(used_keys)\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\tribal-knowledge-tLBhIDXi-py3.11\\Lib\\site-packages\\pymc\\step_methods\\hmc\\nuts.py:180\u001b[0m, in \u001b[0;36mNUTS.__init__\u001b[1;34m(self, vars, max_treedepth, early_max_treedepth, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mvars\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, max_treedepth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, early_max_treedepth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    123\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Set up the No-U-Turn sampler.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m    `pm.sample` to the desired number of tuning steps.\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_treedepth \u001b[38;5;241m=\u001b[39m max_treedepth\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_max_treedepth \u001b[38;5;241m=\u001b[39m early_max_treedepth\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\tribal-knowledge-tLBhIDXi-py3.11\\Lib\\site-packages\\pymc\\step_methods\\hmc\\base_hmc.py:109\u001b[0m, in \u001b[0;36mBaseHMC.__init__\u001b[1;34m(self, vars, scaling, step_scale, is_cov, model, blocked, potential, dtype, Emax, target_accept, gamma, k, t0, adapt_step_size, step_rand, **pytensor_kwargs)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28mvars\u001b[39m \u001b[38;5;241m=\u001b[39m get_value_vars_from_user_vars(\u001b[38;5;28mvars\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model)\n\u001b[1;32m--> 109\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocked\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpytensor_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapt_step_size \u001b[38;5;241m=\u001b[39m adapt_step_size\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mEmax \u001b[38;5;241m=\u001b[39m Emax\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\tribal-knowledge-tLBhIDXi-py3.11\\Lib\\site-packages\\pymc\\step_methods\\arraystep.py:162\u001b[0m, in \u001b[0;36mGradientSharedStep.__init__\u001b[1;34m(self, vars, model, blocked, dtype, logp_dlogp_func, **pytensor_kwargs)\u001b[0m\n\u001b[0;32m    159\u001b[0m model \u001b[38;5;241m=\u001b[39m modelcontext(model)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logp_dlogp_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 162\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogp_dlogp_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpytensor_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    164\u001b[0m     func \u001b[38;5;241m=\u001b[39m logp_dlogp_func\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\tribal-knowledge-tLBhIDXi-py3.11\\Lib\\site-packages\\pymc\\model\\core.py:604\u001b[0m, in \u001b[0;36mModel.logp_dlogp_function\u001b[1;34m(self, grad_vars, tempered, **kwargs)\u001b[0m\n\u001b[0;32m    601\u001b[0m     costs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogp()]\n\u001b[0;32m    603\u001b[0m input_vars \u001b[38;5;241m=\u001b[39m {i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m graph_inputs(costs) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(i, Constant)}\n\u001b[1;32m--> 604\u001b[0m ip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitial_point\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    605\u001b[0m extra_vars_and_values \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    606\u001b[0m     var: ip[var\u001b[38;5;241m.\u001b[39mname]\n\u001b[0;32m    607\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_vars\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m input_vars \u001b[38;5;129;01mand\u001b[39;00m var \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m grad_vars\n\u001b[0;32m    609\u001b[0m }\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ValueGradFunction(costs, grad_vars, extra_vars_and_values, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\tribal-knowledge-tLBhIDXi-py3.11\\Lib\\site-packages\\pymc\\model\\core.py:1063\u001b[0m, in \u001b[0;36mModel.initial_point\u001b[1;34m(self, random_seed)\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the initial point of the model.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m \n\u001b[0;32m   1052\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;124;03m    Maps names of transformed variables to numeric initial values in the transformed space.\u001b[39;00m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m fn \u001b[38;5;241m=\u001b[39m make_initial_point_fn(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, return_transformed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Point(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m)\u001b[49m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\tribal-knowledge-tLBhIDXi-py3.11\\Lib\\site-packages\\pymc\\initial_point.py:170\u001b[0m, in \u001b[0;36mmake_initial_point_fn.<locals>.make_seeded_function.<locals>.inner\u001b[1;34m(seed, *args, **kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(seed, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    169\u001b[0m     reseed_rngs(rngs, seed)\n\u001b[1;32m--> 170\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(varnames, values))\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\tribal-knowledge-tLBhIDXi-py3.11\\Lib\\site-packages\\pytensor\\compile\\function\\types.py:970\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    967\u001b[0m t0_fn \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    969\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 970\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    971\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output_subset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    972\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvm(output_subset\u001b[38;5;241m=\u001b[39moutput_subset)\n\u001b[0;32m    973\u001b[0m     )\n\u001b[0;32m    974\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    975\u001b[0m     restore_defaults()\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\tribal-knowledge-tLBhIDXi-py3.11\\Lib\\site-packages\\pytensor\\link\\vm.py:410\u001b[0m, in \u001b[0;36mLoop.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    408\u001b[0m                 old_s[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m--> 410\u001b[0m         \u001b[43mraise_with_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperform_updates()\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\tribal-knowledge-tLBhIDXi-py3.11\\Lib\\site-packages\\pytensor\\link\\utils.py:531\u001b[0m, in \u001b[0;36mraise_with_op\u001b[1;34m(fgraph, node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    526\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m error does not allow us to add an extra error message\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m     )\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;66;03m# Some exception need extra parameter in inputs. So forget the\u001b[39;00m\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;66;03m# extra long error message in that case.\u001b[39;00m\n\u001b[1;32m--> 531\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_trace)\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\tribal-knowledge-tLBhIDXi-py3.11\\Lib\\site-packages\\pytensor\\link\\vm.py:406\u001b[0m, in \u001b[0;36mLoop.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m thunk, node, old_storage \u001b[38;5;129;01min\u001b[39;00m zip_longest(\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthunks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_thunk_clear, fillvalue\u001b[38;5;241m=\u001b[39m()\n\u001b[0;32m    405\u001b[0m     ):\n\u001b[1;32m--> 406\u001b[0m         \u001b[43mthunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    407\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m old_s \u001b[38;5;129;01min\u001b[39;00m old_storage:\n\u001b[0;32m    408\u001b[0m             old_s[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\tribal-knowledge-tLBhIDXi-py3.11\\Lib\\site-packages\\pytensor\\graph\\op.py:518\u001b[0m, in \u001b[0;36mOp.make_py_thunk.<locals>.rval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;129m@is_thunk_type\u001b[39m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrval\u001b[39m(p\u001b[38;5;241m=\u001b[39mp, i\u001b[38;5;241m=\u001b[39mnode_input_storage, o\u001b[38;5;241m=\u001b[39mnode_output_storage, n\u001b[38;5;241m=\u001b[39mnode):\n\u001b[1;32m--> 518\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39moutputs:\n\u001b[0;32m    520\u001b[0m         compute_map[o][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\tribal-knowledge-tLBhIDXi-py3.11\\Lib\\site-packages\\pytensor\\tensor\\shape.py:461\u001b[0m, in \u001b[0;36mSpecifyShape.perform\u001b[1;34m(self, node, inp, out_)\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecifyShape: Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions (shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m     )\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(xs \u001b[38;5;241m==\u001b[39m s \u001b[38;5;28;01mfor\u001b[39;00m xs, s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape, shape) \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 461\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecifyShape: Got shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mint\u001b[39m(s)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39ms\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39ms\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    463\u001b[0m     )\n\u001b[0;32m    464\u001b[0m out[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n",
      "\u001b[1;31mAssertionError\u001b[0m: SpecifyShape: Got shape (1740,), expected (15,).\nApply node that caused the error: SpecifyShape(AdvancedSubtensor.0, 15)\nToposort index: 19\nInputs types: [TensorType(float64, shape=(None,)), TensorType(int8, shape=())]\nInputs shapes: [(1740,), ()]\nInputs strides: [(8,), ()]\nInputs values: ['not shown', array(15, dtype=int8)]\nInputs type_num: [12, 1]\nOutputs clients: [[Mul(SpecifyShape.0, AdvancedSubtensor.0)]]\n\nDebug print of the apply node: \nSpecifyShape [id A] <Vector(float64, shape=(15,))>\n ├─ AdvancedSubtensor [id B] <Vector(float64, shape=(?,))>\n │  ├─ Alloc [id C] <Vector(float64, shape=(40,))>\n │  │  ├─ 0.5 [id D] <Scalar(float64, shape=())>\n │  │  └─ 40 [id E] <Scalar(int64, shape=())>\n │  └─ [ 0  0  0 ... 34 34 34] [id F] <Vector(int8, shape=(1740,))>\n └─ 15 [id G] <Scalar(int8, shape=())>\n\nHINT: Re-running with most PyTensor optimizations disabled could provide a back-trace showing when this node was created. This can be done by setting the PyTensor flag 'optimizer=fast_compile'. If that does not work, PyTensor optimizations can be disabled with 'optimizer=None'.\nHINT: Use the PyTensor flag `exception_verbosity=high` for a debug print-out and storage map footprint of this Apply node."
     ]
    }
   ],
   "source": [
    "# Fiting the model with MCMC\n",
    "with language_usage_model:\n",
    "    trace = pm.sample(1000, tune=500, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549433a2-7215-43e3-90f7-f44294519f4f",
   "metadata": {},
   "source": [
    "## Model Diagnostics\n",
    " - Checking model convergence (e.g., trace plots, R-hat statistics)\n",
    "Posterior predictive checks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "346d3dd7-04e7-4261-aeab-4cd4592cc754",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trace' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Summary statistics for the posterior distributions\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m summary \u001b[38;5;241m=\u001b[39m az\u001b[38;5;241m.\u001b[39msummary(\u001b[43mtrace\u001b[49m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Trace plots for parameter exploration\u001b[39;00m\n\u001b[0;32m      5\u001b[0m az\u001b[38;5;241m.\u001b[39mplot_trace(trace)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trace' is not defined"
     ]
    }
   ],
   "source": [
    "# Summary statistics for the posterior distributions\n",
    "summary = az.summary(trace)\n",
    "\n",
    "# Trace plots for parameter exploration\n",
    "az.plot_trace(trace)\n",
    "\n",
    "# Model diagnostics (e.g., effective sample size, R-hat)\n",
    "diagnostics = az.rhat(trace)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527d0d40-f642-4632-875b-4a9395e2491c",
   "metadata": {},
   "source": [
    "##  Results and Interpretation\n",
    "- Extracting and summarizing the posterior distributions of model parameters\n",
    "- Identifying significant factors and their impacts on language usage risk metrics\n",
    "- Ridge plots for visualizing the distribution of language usage across projects and repositories, highlighting potential outliers or risks\n",
    "- Additional plots for deeper insights (e.g., comparison of language usage trends across different organizational levels)\n",
    "\n",
    "#### Key Considerations:\n",
    "\n",
    "- **Credible Intervals and Outliers**: Narrow credible intervals suggest high parameter estimate certainty, while wide intervals indicate areas needing further investigation. Outlier detection can pinpoint innovative areas or non-standard practices for strategic exploration.\n",
    "\n",
    "- **Decision-Making**: Insights from the HBM should inform strategic decisions regarding technology adoption, project management, and training to align coding practices with organizational goals, enhancing project continuity and adaptability.\n",
    "\n",
    "This combined understanding of HBM principles, model structure, and practical implications equips readers with the knowledge to interpret complex data analyses meaningfully, driving informed decision-making within the organisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a884ea9-56cf-4070-876a-7f4ae955f318",
   "metadata": {},
   "source": [
    "## Streamlit app"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
